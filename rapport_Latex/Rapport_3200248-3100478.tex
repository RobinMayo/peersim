\documentclass[11pt,a4paper]{report}
\usepackage[left=3cm,right=3cm,top=3cm,bottom=3cm]{geometry}
\usepackage[utf8]{inputenc}
\usepackage[francais]{babel}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{blindtext}
\usepackage{listings}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{caption}

\makeatletter
\renewcommand{\@chapapp}{Exercice}
\makeatother

\captionsetup{position=below}
\setlength{\parskip}{\baselineskip}


\begin{document}

\begin{titlepage}

\centering
\includegraphics[scale=0.4]{SU.png}\par\vspace{1cm}
\vspace{1cm}
{\scshape\bfseries ARA\par}
\vspace{1.5cm}
{\huge\bfseries Projet Peersim\par}
\vspace{2cm}
{\Large\itshape Robin Blottiere-Mayo\par
	Pierre Oumeddour\par}
\vfill
{\Large Professeur : Jonathan Lejeune}
\vfill

% Bottom of the page
{\large \today\par}
\end{titlepage}

\pagenumbering{arabic}

\chapter{}

\section{Question 1 :}

L'algorithme de verrouillage utilisÈé dans la classe Application est un algorithme déÈrivÈé de celui de Naimi-TrÈhel utilisant la notion de jeton.

Ainsi tous les sites se partagent le mÍme jeton et seul le site possÈdant le jeton peut entrer en section critique. Dans la classe Application, les constantes initial\_owner et nil servent ‡ discriminer le site poss√©dant le jeton des autres.

Chaque noeud maintient sa propre liste de noeuds en attente de section critique (variable next) et son compteur global de sections critiques (variable global\_counter). Il poss√®de √©galement l'adresse du noeud dont il pense qu'il poss√®de le jeton (variable last) ainsi que le nombre de sections critiques qu'il a lui-m√™me effectu√©es (variable nb\_cs). Si un noeud veut une section critique, il envoie une demande pour avoir le jeton puis il se met en attente.

Quand un noeud sort de section critique, il envoie le jeton au dernier noeud de la liste des noeuds demandant la section critique avec les informations qu'il poss√®de du nombre de sections critiques r√©alis√©es et des noeuds en attente de section critique.

Lorsqu'un noeud re√ßoit le jeton, il met √† jour son compteur de sections critiques avec la valeur envoy√©e par le dernier noeud ayant √©t√© en section critique. Il compare √©galement sa liste de noeuds en attente avec celle qu'il a re√ßue. Si des noeuds se trouvent dans les deux listes mais pas dans le m√™me ordre, l'ordre envoy√© par le dernier noeud en section critique est maintenu. Si des demandes sont absentes de la liste re√ßue, elles sont ajout√©es en fin de liste.


\section{Question 2 :}

On consid√®re trois √©tats du jeton :
\begin{enumerate}
	\item Un noeud poss√®de le jeton mais ne s‚Äôen sert pas (√©tat tranquille).
	\item Un noeud poss√®de le jeton et est en section critique (√©tat utilis√©).
	\item Le jeton est en transit (√©tat enTransit).
\end{enumerate}
tranquille $\rightarrow$ utilis√© : la section critique est demand√©e et personne ne requiert le jeton.\\
tranquille $\rightarrow$ enTransit : un noeud requiert le jeton.\\
utilis√© $\rightarrow$ tranquille : la section critique se termine.\\
utilis√© $\rightarrow$ enTransit : releaseCS(timeout) \& !next.isEmpty()\\
enTransit $\rightarrow$ utilis√© : receive\_token()\\

\begin{figure}
	\begin{center}
		\includegraphics[scale=0.4]{../Diagrammes/exercice_1-question_2.png} 
	\end{center}
	\caption{\label{etats du jeton} Diagramme des etats du jeton}
\end{figure}


\section{Question 3 :}

$\alpha$ Ètant le temps moyen qu'un processus passe en section critique et $\beta$ le temps passÈ entre les sections critiques.

Le ratio $\rho$ = $\alpha$ / $\beta$ reprÈsente la charge du rÈseau.

Plus ce ratio est √©lev√© plus le r√©seau est ralenti.

\section{Question 4 :}

\textbf{Messages applicatifs}:

Sur cette premi√®re courbe, on observe deux valeurs qui varient en fonction de la charge du r√©seau $\rho$. Il s'agit du nombre moyen de messages applicatifs par section critique. On diff√©rencie le nombre de messages requ√©rant le jeton et le nombre de transmissions du jeton entre les noeuds. Ces rÈsultats ont ÈtÈ obtenus en comptant le nombre d'appel ‡ la mÈthode send().\\

\begin{figure}
	\begin{center}
		\includegraphics[scale=0.6]{Messages_applicatifs.png}
	\end{center}
	\caption{\label{Messages_applicatifs} Messages applicatifs transmits par section critique}
\end{figure}

On observe que plus $\rho$ augmente, plus le nombre de messages applicatifs diminue. A la fin, il n'y a plus qu'un message et un envoi de jeton par section critique. En effet, plus le temps pass√© en section critique est grand par rapport au temps d'attente plus les noeuds savent quel est le noeud qui poss√®de le jeton.\\

Cela s'explique par le fait qu'un noeud ayant fini sa section critique va s'endormir pour un temps qui sera court √©tant donn√© les param√®tres de l'exp√©rience qui incluent un temps de transmission et un temps de repos court entre les sections critiques. En se r√©veillant, le noeud enverra une requ√™te de section critique au noeud dont il pense qu'il poss√®de le jeton. Ce noeud aura en effet toujours le jeton en sa possession car il n'aura probablement pas eu le temps de terminer sa section critique. Ainsi, une seule requ√™te aura suffi au noeud pour √™tre repertori√© comme demandant l'acc√®s √† la section critique. C'est pourquoi on observe quasiment un envoi de requ√™te par section critique.\\

Cette explication est valable pour un temps d'expÈrience suffisament grand pour que les noeuds aient le temps de s'ordonner mutuellement.\\

\textbf{Temps passé dans l'état requesting}:

\begin{figure}
	\begin{center}
		\includegraphics[scale=0.6]{Temps_etat_requesting.png}
	\end{center}
	\caption{\label{etat\_requesting} Temps passée dans l'eétat requesting}
\end{figure}

Sur cette courbe, on observe le temps moyen qu'un noeud passe dans l'Ètat requesting en fonction de la charge du rÈseau. Les temps on ÈtÈ mesurÈs ‡ l'aide de la mÈthode CommonState.getTime(). Les compteurs de temps ont ÈtÈs placÈs ‡ l'envoie et ‡ la rÈception du token et ‡ l'entrÈe et la sortie de la section critique. Un compteur global a ÈtÈ utilisÈ afin de s'assurer que le temps n'Ètait pas comptÈ en double.\\

On peut voir que lorsque que le temps $\beta$ passÈ entre les sections critiques est beaucoup plus grand que le temps $\alpha$ passÈ en section critique, le temps moyen par section critique est trËs faible. Lorsque $\rho$ s'approche de un, le temps passÈ en section critique augmente trËs rapidement. AprËs cela, l'augmentation redevient proche voire infÈrieur √† un sur une Èchelle logarithmique.\\

Cette brusque augmentation peut s'expliquer par le fait qu'un temps $\alpha$ trËs court peut faire qu'‡† un certain moment, aucun des cinquante noeuds du rÈseau ne requiert la section critique. Lorsque la charge du rÈseau sera suffisamment grande pour qu'il y ait en permanence un noeud demandant l'accËs √† la section critique, le temps pass√© dans l'√©tat requesting augmentera linÈairement en fonction du temps o√π le jeton est utilis√© par un processus en section critique.\\


\textbf{Utilisation du jeton}:

\begin{figure}
	\begin{center}
		\includegraphics[scale=0.6]{Temps_token.png}
	\end{center}
	\caption{\label{Temps_token} Temps passé par le jeton dans chacun de ses trois états}
\end{figure}

Sur cette troisiËme courbe, on observe le temps que le jeton passe dans chacun des Ètats dÈcrits ‡† la question 2 en fonction de la charge du rÈseau. L'expÈrience s'appuyant sur un temps de transport nÈgligeable, le temps que le jeton passe dans l'Ètat transmission est proche de 1 quelle que soit la charge du rÈseau.\\

Les temps que le jeton passe en Ètant utilisÈ ou inutilisÈ suivent des courbes inverses. On observe que plus le temps passÈ entre les section critiques $\beta$ est faible plus le jeton est utilisÈ et inversement.


\section{Question 5 :}

Le fait que le temps de transmission moyen soit sup√©rieur au temps moyen pass√© en section critique augmente la charge du r√©seau. Le temps de transport augmentant, le temps o√π le jeton est poss√©d√© par un noeud est plus faible.\\

Cela ne change pas fondamentalement les r√©sultats en dehors de rendre le syst√®me plus lent et de diminuer le nombre de sections critiques pour un temps d'ex√©cution √©gal.\\

Dans le d√©tail, on voit que les premiers instants du fonctionnement du syst√®me le noeud ayant le jeton peut ex√©cuter plusieurs fois sa section critique avant de recevoir une requ√™te et que la file des noeuds demandant l'acc√®s √† la section critique mettra plus de temps √† se remplir. Cependant apr√®s que tous les noeuds aient ex√©cut√© au moins une fois leur section critique, le temps pass√© en section critique et le temps de transmission du message s'additionnant rendront la suite de l'ex√©cution semblable √† ce qu'elle aurait √©t√© avec un temps de transmission moyen plus faible que le temps pass√© en section critique.\\


\chapter{}

\section{Question 1 :}

 Si le noeud fautif est en section critique, il peut ne pas avoir le temps de transmettre le jeton et ainsi de d√©signer un nouveau noeud √©lu. Cela provoquerait le blocage du syst√®me.\\

 Dans la classe Application, l'attribut next n'est modifi√© que dans les m√©thodes : initialisation, releaseCS, receive\_request et receive\_token. Les modifications dans initialisation et receive\_request concernent l'initialisation du syst√®me dans lequel la file est toujours vide. Ainsi, si le noeud fautif poss√®de une file next non vide, il est forc√©ment en section critique, dans ce cas cela provoque le blocage du syst√®me comme expliqu√© dans la question 1.1.\\

En effet, √† la r√©ception d'un token, le noeud ajoute √† sa liste personnelle de noeuds en attente d'ex√©cution, la liste transmise. En sachant que la liste personnelle du noeud est toujours vid√©e √† la fin de la section critique dans la m√©thode releaseCS.\\

Si le noeud fautif posseÃÄde une file next vide, n‚Äôest pointeÃÅ par aucun last et si aucun message √† sa destination n‚Äôest en transit soit :
 Il a fait une demande de section critique et est dans la liste des noeuds en attente du jeton. Dans ce cas le syst√®me finira par aboutir √† un inter blocage.\\

 Il n'a pas fait de demande de section critique. Alors il dispara√Ætra du syst√®me sans impacter son ex√©cution globale.\\


\section{Question 2 :}

random.seed 5\\
network.size 5\\
simulation.endtime 5000\\

protocol.reliableTransport UniformRandomTransport\\
protocol.reliableTransport.mindelay 5\\
protocol.reliableTransport.maxdelay 15\\

protocol.FIFOTransport projetara.util.FIFOTransport\\
protocol.FIFOTransport.transport reliableTransport\\

protocol.CheckpointerImpl projetara.checkpointing.algo1.CheckpointerImpl\\
protocol.CheckpointerImpl.transport FIFOTransport\\
protocol.CheckpointerImpl.checkpointable application\\
protocol.CheckpointerImpl.timecheckpointing 40\\

protocol.application projetara.application.ApplicationCheckpointable\\
protocol.application.timeCS 20\\
protocol.application.timeBetweenCS 10\\
protocol.application.transport CheckpointerImpl\\

control.crash projetara.checkpointing.CrashControler\\
control.crash.probacrash 1\\
control.crash.faulty\_nodes 4\\
control.crash.checkpointer CheckpointerImpl\\
control.crash.at 3000

init.constantes Constantes\\
init.constantes.loglevel INFO\\


\section{Question 3 :}

La m√©thode createCheckpoint n'est pas appel√©e avec une p√©riode fixe et √©gale pour tous les noeuds afin de simuler un syst√®me r√©el dont les horloges internes des processus ne sont pas accessibles et pas forc√©ment synchronis√©s. On utilise donc un random afin de provoquer un checkpoint non coordonn√©.\\

Un checkpoint synchronis√© constituait un cas particulier exceptionnel dans un syst√®me r√©el.\\


\section{Question 4 :}

Les variables √† sauvegarder absolument dans chaque noeud pour que l'algorithme de Juang-Venkatesan fonctionne bien sont le nombre de messages envoy√©s (variable SENT) et le nombre de messages re√ßus (variable RCVD).\\

\section{Question 5 :}

Une pile de tables de hachage pour enregistrer les points de sauvegarde est coh√©rente car l'√©l√©ment accessible est toujours le dernier mis sur la pile, or on cherchera toujours le point de sauvegarde le plus r√©cent.\\

De plus l'algorithme de Juang-Venkatesan enregistre le point de sauvegarde le plus r√©cent dans la m√©moire volatile alors que les points de sauvegarde les plus anciens sont copi√©s dans la m√©moire persistante.\\

Une pile LIFO (Last-In-First-Out) √©mule bien ce proc√©d√© car le point de sauvegarde le plus r√©cent est accessible rapidement alors que l'acc√®s aux points de sauvegarde anciens implique de d√©piler la pile ce qui prend (un peu) plus de temps comme un acc√®s au disque prend plus de temps qu'un acc√®s m√©moire.\\


\section{Question 6 :}

La classe CheckpointerImpl est un d√©corateur de protocole de transport car elle est utilis√©e pour envoyer ses propres messages entre les noeuds. La m√©thode send est donc red√©finie et permet ainsi de compter le nombre de messages entrant et sortant et de sauvegarder les messages envoy√©s depuis le dernier checkpoint.\\


\section{Question 7 :}

En l'absence de l'enveloppe Wrapping, les messages seraient re√ßus directement par la classe Application. Or on a besoin de pouvoir discriminer les messages applicatifs des messages de sauvegarde. Sinon le protocole checkpoint ne peut pas compter le nombre de messages re√ßus par l'application ce qui emp√™cherait la cr√©ation de points de sauvegarde coh√©rents.\\


\section{Question 8 :}

Rappels :
Lors d'un checkpoint, deux types de messages peuvent\-√™tre probl√©matiques : les messages orphelins et les messages manquants.\\
\begin{enumerate}
\item Un message m envoy√© du noeud n1 vers le noeud n2 est dit orphelin si il est re√ßu par le noeud n2 avant son point de sauvegarde en ayant √©t√© envoy√© apr√®s le dernier point de sauvegarde de n1. Dans ce cas la ligne de recouvrement entre n1 et n2 n'est pas coh√©rente et il faut chercher un point de sauvegarde plus r√©cent sur n1 et rev√©rifier qu'il n'y a pas de nouveaux messages orphelins.
\item Lorsqu'on a trouv√© une ligne de recouvrement coh√©rente, il peut rester des messages qui ont √©t√© envoy√©s par un noeud avant son point de sauvegarde qui n'ont pas encore √©t√© re√ßus par le noeud destinataire √† son point de sauvegarde. On parle de messages manquants.
\end{enumerate}\\

Lors de l'appel √† la m√©thode recover de la classe CheckpointerImpl, on commence par stopper l'ex√©cution du noeud courant puis on cr√©e le point de sauvegarde (m√©thode recover). On commence alors la phase de recouvrement.

\subsection{Premi√®re phase, trouver une ligne de recouvrement :}
\begin{enumerate}
\item Les messages rollback sont envoy√©s √† tous les noeuds du syst√®me (m√©thode send\_rollback\_messages) afin de trouver un point de sauvegarde pour chaque noeud qui puisse former une ligne de recouvrement coh√©rente entre les diff√©rents noeuds.
\item On compare pour cela le nombre de messages re√ßus par chaque noeud saved\_rcvd avec le nombre de messages envoy√©s. Tant que l'on trouve des messages orphelins, on d√©truit le point de sauvegarde et on recommence la comparaison avec le point de sauvegarde ant√©rieur (m√©thode receiveRollBackMessage). Apr√®s avoir trouv√© un point de recouvrement coh√©rent, les noeuds avertissent leurs homologues via les messages FinishedRollback.
\item On v√©rifie qu'on a bien re√ßu un message FinishedRollback de tous les autres noeuds du syst√®me (m√©thode receiveFinishedRollbackMessage).
\end{enumerate}

\subsection{Deuxi√®me phase, trouver les messages manquants :}

On cherche √† pr√©sent √† retourner jusqu'√† l'instant o√π l'application a plant√©. Les noeuds savent qu'ils se sont envoy√©s des messages qui ont d√ª √™tre ignor√©s car post√©rieurs au point de sauvegarde.
\begin{enumerate}
\item Chaque noeud demande aux autres si il y a des messages manquants en envoyant le nombre de messages qu'il a re√ßus √† son point de sauvegarde (m√©thode findMessagesToReplay).
\item Les noeuds re√ßoivent le nombre de messages re√ßus par les autres noeuds, les comparent avec le nombre de messages qu'ils leur ont eux-m√™me envoy√©s et renvoient les messages manquants (m√©thode receiveAskMissingMessMessage).
\item Les noeuds ajoutent √† la liste des messages qu'ils ont re√ßus les messages manquants (m√©thode receiveReplyAskMissingMessMessage puis stop\_recover).
\item Finalement, on restaure l'√©tat des noeuds avec les valeurs contenues dans les points de sauvegarde s√©lectionn√©s comprenant le nombre de messages envoy√©s et re√ßus (m√©thode stop\_recover).
\end{enumerate}

\section{Question 9 :}

Apr√®s des d√©bats passionn√©s en cours, nous avons conclu que tel que le code est √©crit, l'ordre FIFO n'est pas indispensable au bon fonctionnement de l'algorithme. En effet, les AskMissingMessMessage ne commencent √† √™tre envoy√©s qu'apr√®s la phase de findMessagesToReplay et les ReplyAskMissingMessMessage ne commencent √† √™tre envoy√©s qu'apr√®s la r√©ception de tous les AskMissingMessMessage. Il y a donc des points de synchronisation de l'application avant et apr√®s les AskMissingMessMessage.\\

Si le noeud renvoyait lui-m√™me les messages manquants, une absence de protocole FIFO pourrait provoquer une inversion des messages envoy√©s.\\


\chapter{}


\end{document}
